{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2: Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T10:18:09.894510Z",
     "start_time": "2021-05-10T10:18:09.891712Z"
    }
   },
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:05.395754Z",
     "start_time": "2021-05-14T15:12:05.384001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github. Loading special files as well\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:05.918998Z",
     "start_time": "2021-05-14T15:12:05.903897Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./utils.py'):\n",
    "    print(\"utils file not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/homeworks/Lab02_NMT/utils.py -nc\n",
    "\n",
    "if not os.path.exists('./my_network.py'):\n",
    "    print(\"network file not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/homeworks/Lab02_NMT/my_network.py -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:06.258970Z",
     "start_time": "2021-05-14T15:12:06.247335Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:06.996082Z",
     "start_time": "2021-05-14T15:12:06.991577Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:10.871516Z",
     "start_time": "2021-05-14T15:12:07.318507Z"
    }
   },
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:10.986151Z",
     "start_time": "2021-05-14T15:12:10.895786Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:11.017024Z",
     "start_time": "2021-05-14T15:12:11.010742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:11.820858Z",
     "start_time": "2021-05-14T15:12:11.043506Z"
    }
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:11.858287Z",
     "start_time": "2021-05-14T15:12:11.850863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9290\n",
      "Unique tokens in target (en) vocabulary: 6708\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:11.899446Z",
     "start_time": "2021-05-14T15:12:11.890286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'им',\n",
       " 'гавань',\n",
       " 'комфортабельный',\n",
       " 'charming',\n",
       " 'чистый',\n",
       " 'milano',\n",
       " 'удовлетворят',\n",
       " 'дения',\n",
       " 'стимбоут']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:27.938185Z",
     "start_time": "2021-05-14T15:12:27.932280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'breakfasts',\n",
       " 'comfortably',\n",
       " 'chamonix',\n",
       " 'marta',\n",
       " 'schwedenplatz',\n",
       " 'lua']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:28.637804Z",
     "start_time": "2021-05-14T15:12:28.633239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['the', 'tents', 'are', 'customised', 'with', 'earth', 'walls', 'and', 'typical', 'décor', '.'], 'src': ['шатры', 'с', 'земляными', 'стенами', 'оформлены', 'в', 'традиционном', 'стиле', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:30.600598Z",
     "start_time": "2021-05-14T15:12:29.776865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in train_data.examples])\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:31.135756Z",
     "start_time": "2021-05-14T15:12:30.622329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Test data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in test_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in test_data.examples])\n",
    "\n",
    "print('Length distribution in Test data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:34.302708Z",
     "start_time": "2021-05-14T15:12:34.298536Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:34.602417Z",
     "start_time": "2021-05-14T15:12:34.596936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:35.018238Z",
     "start_time": "2021-05-14T15:12:35.013708Z"
    }
   },
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:35.600070Z",
     "start_time": "2021-05-14T15:12:35.500314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.trg]:[torch.LongTensor of size 54x128]\n",
      "\t[.src]:[torch.LongTensor of size 44x128]\n",
      "torch.Size([44, 128]) torch.Size([54, 128])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:35.819304Z",
     "start_time": "2021-05-14T15:12:35.797556Z"
    }
   },
   "outputs": [],
   "source": [
    "import my_network\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:36.971760Z",
     "start_time": "2021-05-14T15:12:36.800360Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:38.701964Z",
     "start_time": "2021-05-14T15:12:38.393927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9290, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6708, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=6708, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:12:41.165592Z",
     "start_time": "2021-05-14T15:12:41.160411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,893,108 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:43:40.230151Z",
     "start_time": "2021-05-12T15:43:40.226094Z"
    }
   },
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:43:42.945843Z",
     "start_time": "2021-05-12T15:43:42.937178Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:43:43.732221Z",
     "start_time": "2021-05-12T15:43:43.725783Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:43:44.917865Z",
     "start_time": "2021-05-12T15:43:44.914269Z"
    }
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:43:45.526562Z",
     "start_time": "2021-05-12T15:43:45.522871Z"
    }
   },
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T15:44:10.353225Z",
     "start_time": "2021-05-12T15:43:46.214867Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-888f7ba0850f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-98cbc618a52c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, train_history, valid_history)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Let's clip the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/edu/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/edu/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "     \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "del utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: there is a 24 - hour front desk at the property .\n",
      "Generated: the property offers a 24 - hour front desk . .\n",
      "\n",
      "Original: this property also features free wifi .\n",
      "Generated: free wifi access . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2]:\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:03, 18.87it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "        \n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend([get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.139920232081806"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __24__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __22__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __27__ - good score, 70% of points\n",
    "\n",
    "* __29__ - excellent score, 100% of points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
